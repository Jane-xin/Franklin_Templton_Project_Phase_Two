{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9627dd-5608-4da8-9f1a-8ea9589a003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from llama_cloud_services import LlamaExtract\n",
    "#from schemas import Enrollment2024_25  #This could be adjusted through schemas.py\n",
    "from enrollment_latest import Enrollment2024_25\n",
    "#from enrollment_optimal import Enrollment2024_25\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf875a82-1028-4b54-8807-1d1dde9cca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PDF_ROOT = \"scraper/university_pdfs_hy_e\"\n",
    "#PDF_ROOT = \"sample\"\n",
    "PDF_ROOT = \"university_pdfs_sample\"\n",
    "OUTPUT_ROOT = \"output_scrapping\"\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)  \n",
    "#AGENT_ID = \"ca221e4c-b3b2-4bf1-8862-d26016c9943a\" #Different based on your LLamaCloud account - enrollment\n",
    "\n",
    "#AGENT_ID = \"09371b77-6cdd-4fee-89db-93b1f88544f5\" # enrollment with all variables have yrs\n",
    "#AGENT_ID = \"1a3fb0ee-4ec7-4d73-8ccb-81dfaa1f3e01\" #enrollment with important variables have yrs\n",
    "AGENT_ID = \"99a9123b-734a-462b-a3c0-2887f5e6a634\" #enrollment grabs latest data no matter which yr\n",
    "\n",
    "load_dotenv() #make sure the API key is in the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47855a29-4fc8-4dae-b036-4626be1954da",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = LlamaExtract(project_id = '8c10e62e-3810-4193-915d-d2d11105826d')\n",
    "\n",
    "#uncomment the below line if you are creating the agent for the first time\n",
    "# agent = extractor.create_agent(name = \"enrollment-parser-2024\", data_schema=Enrollment2024_25)\n",
    "\n",
    "agent = extractor.get_agent(id = AGENT_ID)\n",
    "\n",
    "#uncomment the following lines if you updated the schema\n",
    "agent.data_schema = Enrollment2024_25\n",
    "agent.save()\n",
    "agent = extractor.get_agent(id = AGENT_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81a8d24-9e3e-40eb-a1c0-9fe4e2025a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.data_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b385406-d4f6-48e5-94b5-f999ee2e9f04",
   "metadata": {},
   "source": [
    "The following cell block extracts all the schools' info into one excel sheet but in different tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed9f78-2b07-4696-8bd9-2ad2281d255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the output Excel file path\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_ROOT, \"all_schools_sample.xlsx\")\n",
    "\n",
    "# Create an Excel writer using the openpyxl engine\n",
    "writer = pd.ExcelWriter(OUTPUT_FILE, engine=\"openpyxl\")\n",
    "\n",
    "# Iterate through each folder (school) in the PDF_ROOT directory\n",
    "for school in sorted(os.listdir(PDF_ROOT)):\n",
    "    school_dir = os.path.join(PDF_ROOT, school)\n",
    "    \n",
    "    # Skip if not a directory (e.g., if it's a file)\n",
    "    if not os.path.isdir(school_dir):\n",
    "        continue\n",
    "\n",
    "    combined   = {}       # Dictionary to accumulate extracted values\n",
    "    first_keys = None     # Tracks the metric keys from the first valid PDF\n",
    "\n",
    "    # Loop over each PDF file within the school's folder\n",
    "    for fname in sorted(os.listdir(school_dir)):\n",
    "        if not fname.lower().endswith(\".pdf\"):\n",
    "            continue  # Skip non-PDF files\n",
    "\n",
    "        path = os.path.join(school_dir, fname)\n",
    "        print(f\"Extracting data from {school}/{fname}\")\n",
    "        try:\n",
    "            # Extract data from the PDF using the agent\n",
    "            run  = agent.extract(path)\n",
    "            data = run.data or {}  # Use empty dict if data is None\n",
    "\n",
    "            # Initialize keys on the first successful PDF extraction\n",
    "            if first_keys is None:\n",
    "                first_keys = list(data.keys())\n",
    "                combined   = {k: None for k in first_keys}\n",
    "\n",
    "            # Update combined dictionary with non-empty values\n",
    "            for k, v in data.items():\n",
    "                if v not in (None, \"\", []):\n",
    "                    combined[k] = v\n",
    "\n",
    "        except Exception as err:\n",
    "            print(f\"Skipped {fname}: {err}\")  # Log extraction errors\n",
    "\n",
    "    # If we have extracted any data at all, write to Excel\n",
    "    if first_keys:\n",
    "        # Create a DataFrame from the combined dictionary\n",
    "        df = pd.DataFrame.from_dict(combined, orient=\"index\", columns=[\"2024-25\"])\n",
    "        df.index.name = \"Metric\"  # Set index name for clarity\n",
    "\n",
    "        # Sheet name must be ≤31 characters due to Excel limitations\n",
    "        sheet_name = school[:31]\n",
    "        df.to_excel(writer, sheet_name=sheet_name)\n",
    "    else:\n",
    "        print(f\"No data for {school}.\")  # Log schools with no extractable content\n",
    "\n",
    "# Save the Excel file with all the individual sheets\n",
    "writer.close()\n",
    "print(f\"All schools written to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6c073-4b51-4770-abc4-f5942a1f772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all the tabs into one sheet if wanted\n",
    "file_path   = \"output_scrapping/all_schools_sample.xlsx\"\n",
    "output_path = \"output_scrapping/all_schools_combined_sample.xlsx\"\n",
    "\n",
    "raw = pd.read_excel(file_path, sheet_name=None, index_col=0)\n",
    "\n",
    "school_series = {\n",
    "    school: df.iloc[:, 0]                      # first (only) value column\n",
    "    for school, df in raw.items()\n",
    "}\n",
    "\n",
    "df_comb = pd.DataFrame(school_series).T\n",
    "df_comb.index.name = \"School\"                 \n",
    "#df_comb.insert(0, \"Year\", \"2024‑2025\")\n",
    "# df_comb.loc['Texas_A&M', ['Total_Headcount','Undergraduate_Headcount']] = \\\n",
    "#     df_comb.loc['Texas_A&M', ['Undergraduate_Headcount','Total_Headcount']].values\n",
    "\n",
    "# df_comb.loc['California_state_university', 'Undergraduate_Headcount'] = None \n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    df_comb.to_excel(writer, sheet_name=\"Combined\")\n",
    "\n",
    "print(\"Saved:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5825cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"output_scrapping/all_schools_combined_sample.xlsx\")\n",
    "valid_years = {\n",
    "    \"Fall 2024\", \"AY 2024–2025\", \"2024–2025\", \"2024-25\", \"AY 24–25\", \"Fall 24\", \"2024\"\n",
    "}\n",
    "\n",
    "for col in df.columns:\n",
    "    if col.startswith(\"Year_\"):\n",
    "        value_col = col.replace(\"Year_\", \"\")\n",
    "        if value_col in df.columns:\n",
    "            mask_invalid = ~df[col].isin(valid_years)\n",
    "            df.loc[mask_invalid, value_col] = None\n",
    "\n",
    "\n",
    "df.to_excel(\"output_scrapping/all_schools_cleaned_fall_2024.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a740c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_excel(\"output_scrapping/all_schools_combined_sample.xlsx\")\n",
    "# import re\n",
    "# import numpy as np\n",
    "\n",
    "# equivalence_map = {\n",
    "#     r\"2024-25|2024-2025|Fall 2024 (FY2024-25)|AY 2024–25|Fall 2024|Fiscal 2025|2024\": \"2024-2025\",\n",
    "#     r\"2023-24|2023-2024|AY 2023–24|Fall 2023|Fiscal 2024|2023\": \"2023-2024\"\n",
    "# }\n",
    "\n",
    "# # def standardize_year(value):\n",
    "# #     if isinstance(value, str):\n",
    "# #         for pattern, standard in equivalence_map.items():\n",
    "# #             if re.search(pattern, value):\n",
    "# #                 return standard\n",
    "# #     return np.nan\n",
    "\n",
    "# # # Apply to each column that starts with 'Year_'\n",
    "# # for col in df.columns:\n",
    "# #     if col.startswith(\"Year_\"):\n",
    "# #         category = col.replace(\"Year_\", \"\")\n",
    "# #         new_col = f\"year_{'fee' if 'Tuition' in category or 'Room' in category else 'headcount'}\"\n",
    "# #         df[new_col] = df[col].apply(standardize_year)\n",
    "\n",
    "# # # Combine year_headcount and year_fee into year_combine\n",
    "# # def combine_years(row):\n",
    "# #     if pd.notnull(row['year_headcount']):\n",
    "# #         return row['year_headcount']\n",
    "# #     elif pd.notnull(row['year_fee']):\n",
    "# #         return row['year_fee']\n",
    "# #     else:\n",
    "# #         return np.nan\n",
    "\n",
    "# # df['year_combine'] = df.apply(combine_years, axis=1)\n",
    "# # import pandas as pd\n",
    "# import re\n",
    "# from pathlib import Path\n",
    "\n",
    "\n",
    "# # Define function to standardize year format\n",
    "# def normalize_year(text):\n",
    "#     if pd.isna(text):\n",
    "#         return None\n",
    "#     text = str(text)\n",
    "#     matches = re.findall(r\"20\\d{2}\", text)\n",
    "#     if len(matches) >= 2:\n",
    "#         return f\"{matches[0]}-{matches[1]}\"\n",
    "#     elif len(matches) == 1:\n",
    "#         try:\n",
    "#             y1 = int(matches[0])\n",
    "#             return f\"{y1}-{y1+1}\"\n",
    "#         except:\n",
    "#             return None\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # Apply normalization for headcount, fee, and combine\n",
    "# year_headcount_cols = [col for col in df.columns if \"Year_\" in col and any(x in col for x in [\"Headcount\", \"Full\", \"Total\"])]\n",
    "# year_fee_cols = [col for col in df.columns if \"Year_\" in col and any(x in col for x in [\"Tuition\", \"Room\"])]\n",
    "\n",
    "# df[\"year_headcount\"] = df[year_headcount_cols].bfill(axis=1).iloc[:, 0].apply(normalize_year)\n",
    "# df[\"year_fee\"] = df[year_fee_cols].bfill(axis=1).iloc[:, 0].apply(normalize_year)\n",
    "\n",
    "# def combine_years(row):\n",
    "#     y1 = row[\"year_headcount\"]\n",
    "#     y2 = row[\"year_fee\"]\n",
    "#     return y1 if y1 else y2\n",
    "\n",
    "# df[\"year_combine\"] = df.apply(combine_years, axis=1)\n",
    "\n",
    "# df.to_excel(\"output_scrapping/all_schools_cleaned_fall_2024.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133d13e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
