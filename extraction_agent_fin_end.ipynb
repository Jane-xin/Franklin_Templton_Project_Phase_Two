{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2b22931-96b4-4c19-a74f-44e0185ab2b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_cloud_services in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (0.6.23)\n",
      "Requirement already satisfied: openpyxl in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (3.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama_cloud_services) (8.1.8)\n",
      "Requirement already satisfied: llama-cloud==0.1.22 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama_cloud_services) (0.1.22)\n",
      "Requirement already satisfied: llama-index-core>=0.12.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama_cloud_services) (0.12.37)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.7 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama_cloud_services) (4.3.7)\n",
      "Requirement already satisfied: pydantic!=2.10,>=2.8 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama_cloud_services) (2.11.4)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama_cloud_services) (1.1.0)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-cloud==0.1.22->llama_cloud_services) (2025.4.26)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-cloud==0.1.22->llama_cloud_services) (0.28.1)\n",
      "Requirement already satisfied: et-xmlfile in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: anyio in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx>=0.20.0->llama-cloud==0.1.22->llama_cloud_services) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx>=0.20.0->llama-cloud==0.1.22->llama_cloud_services) (1.0.8)\n",
      "Requirement already satisfied: idna in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx>=0.20.0->llama-cloud==0.1.22->llama_cloud_services) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud==0.1.22->llama_cloud_services) (0.14.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (3.11.18)\n",
      "Requirement already satisfied: aiosqlite in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (2025.3.2)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.12.0->llama_cloud_services) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from llama-index-core>=0.12.0->llama_cloud_services) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama_cloud_services) (1.20.0)\n",
      "Requirement already satisfied: griffe in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core>=0.12.0->llama_cloud_services) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core>=0.12.0->llama_cloud_services) (3.1.6)\n",
      "Requirement already satisfied: joblib in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama_cloud_services) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama_cloud_services) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic!=2.10,>=2.8->llama_cloud_services) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic!=2.10,>=2.8->llama_cloud_services) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic!=2.10,>=2.8->llama_cloud_services) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core>=0.12.0->llama_cloud_services) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core>=0.12.0->llama_cloud_services) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.12.0->llama_cloud_services) (3.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.12.0->llama_cloud_services) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from anyio->httpx>=0.20.0->llama-cloud==0.1.22->llama_cloud_services) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from dataclasses-json->llama-index-core>=0.12.0->llama_cloud_services) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.12.0->llama_cloud_services) (24.2)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core>=0.12.0->llama_cloud_services) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/neelabhkashyap/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core>=0.12.0->llama_cloud_services) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_cloud_services openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c9627dd-5608-4da8-9f1a-8ea9589a003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from llama_cloud_services import LlamaExtract\n",
    "from financial_schemas_end_v8 import EndowmentAndInvestmentLevels_2024_25  #This could be adjusted through schemas.py\n",
    "#from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf875a82-1028-4b54-8807-1d1dde9cca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_ROOT = \"private_universities/university_pdfs\"\n",
    "OUTPUT_ROOT = \"output_fin_nk_v8\"\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)  \n",
    "AGENT_ID = \"56843d2c-7e9b-445d-b634-9833dd1cb4db\" #Different based on your LLamaCloud account\n",
    "api_key = os.getenv(\"LLAMACLOUD_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47855a29-4fc8-4dae-b036-4626be1954da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/8j3nd3m95y1brb0j52fx43fr0000gn/T/ipykernel_2739/1285879971.py:13: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  agent.data_schema = EndowmentAndInvestmentLevels_2024_25.schema()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:09<00:00,  9.14s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:11<00:00, 11.06s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:11<00:00, 11.50s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:11<00:00, 11.18s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:27<00:00, 27.22s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.88s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.99s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.57s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.78s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.96s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:12<00:00, 12.18s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:09<00:00,  9.81s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.05s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.86s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:04<00:00,  4.27s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:20<00:00, 20.07s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.75s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.27s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:05<00:00,  5.55s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:11<00:00, 11.41s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:16<00:00, 16.69s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:16<00:00, 16.48s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.45s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.54s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.54s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.65s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.81s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.55s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.15s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:05<00:00,  5.78s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:22<00:00, 22.22s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.57s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.45s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:14<00:00, 14.33s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:09<00:00,  9.21s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.39s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:11<00:00, 11.56s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:09<00:00,  9.52s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.64s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:11<00:00, 11.13s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:12<00:00, 12.92s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.45s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:11<00:00, 11.88s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:09<00:00,  9.42s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:19<00:00, 19.57s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.27s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:15<00:00, 15.83s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:16<00:00, 16.30s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:06<00:00,  6.79s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:07<00:00,  7.56s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [02:22<00:00, 142.53s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:16<00:00, 16.92s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:03<00:00,  3.60s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.19s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:06<00:00,  6.22s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:07<00:00,  7.69s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:13<00:00, 13.47s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.33s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:20<00:00, 20.81s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.40s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:09<00:00,  9.24s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:08<00:00,  8.81s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.37s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.04s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.46s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.28s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.54s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:12<00:00, 12.14s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:10<00:00, 10.58s/it]\n",
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:06<00:00,  6.86s/it]\n"
     ]
    }
   ],
   "source": [
    "extractor = LlamaExtract(\n",
    "    api_key=\"llx-63CU3PdyDo0d230ureocmy9JOHgnPwYgE2HETi55DqzYCIpy\",  \n",
    "    project_id=\"8c10e62e-3810-4193-915d-d2d11105826d\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#agent = extractor.create_agent(name = \"endowment-parser-2024\", data_schema=EndowmentAndInvestmentLevels_2024_25)\n",
    "\n",
    "agent = extractor.get_agent(id = AGENT_ID)\n",
    "\n",
    "#uncomment the following lines if you updated the schema\n",
    "agent.data_schema = EndowmentAndInvestmentLevels_2024_25.schema()\n",
    "agent.save()\n",
    "agent = extractor.get_agent(id = AGENT_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f81a8d24-9e3e-40eb-a1c0-9fe4e2025a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additionalProperties': False,\n",
       " 'properties': {'endowment_net_assets_eoy_total': {'anyOf': [{'type': 'integer'},\n",
       "    {'type': 'null'}],\n",
       "   'description': \"Total endowment net assets for the 2024–2025 fiscal year (in thousands). Only extract from a table labeled 'Changes in Endowment Net Assets' in the Notes section. **Include only values clearly labeled as 2024, FY2024, or 'as of June 30, 2024'. Ignore 2023 and earlier values.** Do not extract from general balance sheets or summaries. Values must be standardized to $000s.\"},\n",
       "  'endowment_net_assets_eoy_with_donor_restrictions': {'anyOf': [{'type': 'integer'},\n",
       "    {'type': 'null'}],\n",
       "   'description': \"Total donor-restricted endowment net assets as of the end of fiscal year 2024–2025 (in thousands). Must be from a 'Changes in Endowment Net Assets' table in the Notes section. **Exclude any data from 2023 or earlier.**\"},\n",
       "  'endowment_net_assets_eoy_with_donor_restrictions_temporarily_restricted': {'anyOf': [{'type': 'integer'},\n",
       "    {'type': 'null'}],\n",
       "   'description': \"Temporarily restricted portion of endowment net assets (in thousands), for fiscal year 2024–2025. Only extract if labeled as 2024 or 'June 30, 2024'. Must come from detailed note tables.\"},\n",
       "  'endowment_net_assets_eoy_with_donor_restrictions_permanently_restricted': {'anyOf': [{'type': 'integer'},\n",
       "    {'type': 'null'}],\n",
       "   'description': 'Permanently restricted portion of endowment net assets (in thousands), for fiscal year 2024–2025. Only extract if clearly labeled and appears in a table in the notes section. Exclude 2023 data.'},\n",
       "  'endowment_net_assets_eoy_without_donor_restrictions': {'anyOf': [{'type': 'integer'},\n",
       "    {'type': 'null'}],\n",
       "   'description': 'Unrestricted endowment net assets (in thousands), for the 2024–2025 fiscal year. Must come from a detailed endowment activity table in the Notes. Ignore earlier years.'},\n",
       "  'appropriation_of_endowment_for_expenditure_total': {'anyOf': [{'type': 'integer'},\n",
       "    {'type': 'null'}],\n",
       "   'description': \"Total appropriation/spending from endowment for 2024–2025 (in thousands). Must be from a table labeled 'Changes in Endowment Net Assets' or similar, and clearly labeled as 2024. **Ignore 2023 and earlier values.**\"},\n",
       "  'appropriation_of_endowment_for_expenditure_with_donor_restrictions': {'anyOf': [{'type': 'integer'},\n",
       "    {'type': 'null'}],\n",
       "   'description': 'Endowment appropriation from donor-restricted funds during fiscal year 2024–2025 (in thousands). Only extract if the table specifies 2024. Exclude values from previous fiscal years.'},\n",
       "  'appropriation_of_endowment_for_expenditure_without_donor_restrictions': {'anyOf': [{'type': 'integer'},\n",
       "    {'type': 'null'}],\n",
       "   'description': 'Appropriated endowment spending from unrestricted sources during fiscal year 2024–2025 (in thousands). Only extract from the Notes and labeled clearly as 2024. Ignore prior years.'},\n",
       "  'investment_level_1': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "   'description': 'Fair value of Level 1 investments (quoted market prices) at year-end 2024–2025 (in thousands). Only extract from fair value hierarchy tables in the Notes labeled with 2024. Check the same table that has Fair Value as a header or a similar label.**Do not extract values from 2023 tables or unrelated entities (e.g., ASU Enterprise Partners).**'},\n",
       "  'investment_level_2': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "   'description': 'Fair value of Level 2 investments (observable inputs) at fiscal year end 2024–2025 (in thousands). Check the same table that has Fair Value as a header or a similar label.Must come from the university’s own Notes. Ensure 2024 label is visible. Exclude prior years.'},\n",
       "  'investment_level_3': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "   'description': 'Fair value of Level 3 investments (unobservable inputs) at June 30, 2024 (in thousands). Check the same table that has Fair Value as a header or a similar label.Must be labeled with 2024 and come from the fair value hierarchy tables under Notes. Do not mix sources across years.'},\n",
       "  'investments_measured_at_nav': {'anyOf': [{'type': 'integer'},\n",
       "    {'type': 'null'}],\n",
       "   'description': 'Total value of university investments measured at NAV as of fiscal year 2024–2025 (in thousands). Must come from a Fair Value table in Notes. Include Life Insurance Cash Surrender value if it appears separately. Check the same table that has Fair Value as a header or a similar label.**Only use 2024 figures.**'},\n",
       "  'investments_total_fair_value': {'anyOf': [{'type': 'integer'},\n",
       "    {'type': 'null'}],\n",
       "   'description': 'Grand total fair value of all university investments at end of 2024–2025 (in thousands). Check the same table that has Fair Value as a header or a similar label.Only extract if clearly labeled and appears in the university’s fair value hierarchy table in the Notes. **Ignore totals from other years, foundations, or systems.**'}},\n",
       " 'required': ['endowment_net_assets_eoy_total',\n",
       "  'endowment_net_assets_eoy_with_donor_restrictions',\n",
       "  'endowment_net_assets_eoy_with_donor_restrictions_temporarily_restricted',\n",
       "  'endowment_net_assets_eoy_with_donor_restrictions_permanently_restricted',\n",
       "  'endowment_net_assets_eoy_without_donor_restrictions',\n",
       "  'appropriation_of_endowment_for_expenditure_total',\n",
       "  'appropriation_of_endowment_for_expenditure_with_donor_restrictions',\n",
       "  'appropriation_of_endowment_for_expenditure_without_donor_restrictions',\n",
       "  'investment_level_1',\n",
       "  'investment_level_2',\n",
       "  'investment_level_3',\n",
       "  'investments_measured_at_nav',\n",
       "  'investments_total_fair_value'],\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.data_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449229a-af1c-4e6f-8219-6497a0a1bc94",
   "metadata": {},
   "source": [
    "The following two cell blocks extract all schools' info into one excel file per school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36077e96-e5ec-4352-afef-d76b8f78be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_school(school_name, school_dir):\n",
    "    combined   = {}\n",
    "    first_keys = None\n",
    "\n",
    "    for fname in sorted(os.listdir(school_dir)):\n",
    "        if not fname.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "        path = os.path.join(school_dir, fname)\n",
    "        print(f\"Extracting data from {fname}\")\n",
    "        try:\n",
    "            run  = agent.extract(path)\n",
    "            data = run.data or {}\n",
    "            if first_keys is None:\n",
    "                first_keys = list(data.keys())\n",
    "                combined  = {k: None for k in first_keys}\n",
    "            for k, v in data.items():\n",
    "                if v not in (None, \"\", []):\n",
    "                    combined[k] = v\n",
    "        except Exception as err:\n",
    "            print(f\"Skipped {fname}: {err}\")\n",
    "\n",
    "    if first_keys:\n",
    "        df = pd.DataFrame.from_dict(combined, orient=\"index\", columns=[\"2024-25\"])\n",
    "        df.index.name = \"Metric\"\n",
    "        outfile = os.path.join(OUTPUT_ROOT, f\"{school_name}.xlsx\")\n",
    "        df.to_excel(outfile)\n",
    "        print(f\"Saved output to {outfile}\")\n",
    "    else:\n",
    "        print(f\"No PDF data found for {school_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7256b8f-8158-48f2-8b89-5e1ae36760c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing school: BRADLEY_UNIVERSITY\n",
      "Extracting data from Annual_Financial_Information_and_Operating_Data__Rule_15c2-12__for_FY24_for_the_year_ended_05_31_2024__227_KB_.pdf\n",
      "Extracting data from Audited_Financial_Statements_or_ACFR__Rule_15c2-12__for_FY24_for_the_year_ended_05_31_2024__541_KB_.pdf\n",
      "Saved output to output_fin_nk_v8/BRADLEY_UNIVERSITY.xlsx\n",
      "Processing school: CORNELL_UNIVERSITY\n",
      "Extracting data from 2024_Audited_Financial_Statements_for_the_year_ended_06_30_2024__788_KB_.pdf\n",
      "Extracting data from 2024_Operating_Data_for_the_year_ended_06_30_2024__109_KB_.pdf\n",
      "Extracting data from Incorporate_OS_by_Reference_as_of_04_25_2024__2.4_MB_.pdf\n",
      "Saved output to output_fin_nk_v8/CORNELL_UNIVERSITY.xlsx\n",
      "Processing school: CULINARY_INSTITUTE_OF_AMERICA_THE\n",
      "Extracting data from 2024_Annual_Report_-_Corrected_for_the_year_ended_05_31_2024__130_KB_.pdf\n",
      "Extracting data from 2024_Annual_Report_for_the_year_ended_05_31_2024__129_KB_.pdf\n",
      "Extracting data from 2024_Audited_Financial_Statements_for_the_year_ended_05_31_2024__277_KB_.pdf\n",
      "Saved output to output_fin_nk_v8/CULINARY_INSTITUTE_OF_AMERICA_THE.xlsx\n",
      "Processing school: GANNON_UNIVERSITY\n",
      "Extracting data from Audited_Financial_Statements_for_the_year_ended_06_30_2024__786_KB_.pdf\n",
      "Extracting data from Continued_Disclosures_Fall_2024_for_the_year_ended_06_30_2024_Document1__203_KB_.pdf\n",
      "Saved output to output_fin_nk_v8/GANNON_UNIVERSITY.xlsx\n",
      "Processing school: LEWIS_UNIVERSITY\n",
      "Extracting data from Audited_Financial_Statements_for_the_year_ended_06_30_2024__430_KB_.pdf\n",
      "Extracting data from Continuing_Disclosure_for_the_year_ended_06_30_2024__298_KB_.pdf\n",
      "Saved output to output_fin_nk_v8/LEWIS_UNIVERSITY.xlsx\n",
      "Processing school: MOLLOY_COLLEGE\n",
      "Extracting data from Financial_Operating_Filing_for_the_year_ended_06_30_2024_Document1__304_KB_.pdf\n",
      "Extracting data from Financial_Operating_Filing_for_the_year_ended_06_30_2024_Document2__142_KB_.pdf\n",
      "Saved output to output_fin_nk_v8/MOLLOY_COLLEGE.xlsx\n",
      "Processing school: MOUNT_ST_MARY_S_UNIVERSITY_INC\n",
      "Extracting data from Audited_Annual_Financials_for_the_year_ended_06_30_2024_Document1__29.1_MB_.pdf\n",
      "Extracting data from Audited_Annual_Financials_for_the_year_ended_06_30_2024_Document2__5_MB_.pdf\n",
      "Skipped Audited_Annual_Financials_for_the_year_ended_06_30_2024_Document2__5_MB_.pdf: Network error: \n",
      "Saved output to output_fin_nk_v8/MOUNT_ST_MARY_S_UNIVERSITY_INC.xlsx\n",
      "Processing school: NEW_YORK_UNIVERSITY\n",
      "Extracting data from 2024_Certificate_of_Compliance_-_Audit_for_the_year_ended_06_30_2024__330_KB_.pdf\n",
      "Extracting data from 2024_Certificate_of_Compliance_for_the_year_ended_06_30_2024__323_KB_.pdf\n",
      "Extracting data from 2024_Consolidated_Financial_Statements_New_York_University_for_the_year_ended_06_30_2024__466_KB_.pdf\n",
      "Extracting data from 2024_Operating_Data_for_the_year_ended_06_30_2024__244_KB_.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting files:   0%|          | 0/1 [05:04<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 2024_Operating_Data_for_the_year_ended_06_30_2024__244_KB_.pdf: Request timed out: \n",
      "Saved output to output_fin_nk_v8/NEW_YORK_UNIVERSITY.xlsx\n",
      "Processing school: PRESIDENT___FELLOWS_OF_HARVARD_COLLEGE\n",
      "Extracting data from Harvard_University_Audited_Financial_Information_for_the_year_ended_06_30_2024__10.6_MB_.pdf\n",
      "Extracting data from Harvard_University_Financial_Report_for_the_year_ended_06_30_2024__10.6_MB_.pdf\n",
      "Extracting data from Harvard_University_Student_Applications_and_Enrollment_for_the_year_ended_06_30_2024__557_KB_.pdf\n",
      "Saved output to output_fin_nk_v8/PRESIDENT___FELLOWS_OF_HARVARD_COLLEGE.xlsx\n",
      "Processing school: STEVENSON_UNIVERSITY_INC\n",
      "Extracting data from 2024_Annual_Compliance_Certificate__EagleBank__for_the_year_ended_06_30_2024__3_MB_.pdf\n",
      "Extracting data from 2024_Annual_Compliance_Certificate_for_the_year_ended_06_30_2024__2.8_MB_.pdf\n",
      "Extracting data from 2024_Audited_Financial_Statements_for_the_year_ended_06_30_2024__348_KB_.pdf\n",
      "Extracting data from 2024_Operating_Data_for_the_year_ended_06_30_2024__196_KB_.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting files:   0%|          | 0/1 [09:39<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output to output_fin_nk_v8/STEVENSON_UNIVERSITY_INC.xlsx\n",
      "Processing school: STEVENS_INSTITUTE_OF_TECHNOLOGY\n",
      "Extracting data from Annual_Report_for_the_year_ended_06_30_2024__216_KB_.pdf\n",
      "Extracting data from Audit_Financial_Statement_for_the_year_ended_06_30_2024__626_KB_.pdf\n",
      "Saved output to output_fin_nk_v8/STEVENS_INSTITUTE_OF_TECHNOLOGY.xlsx\n",
      "Processing school: ST_LOUIS_UNIVERSITY_US\n",
      "Extracting data from Amendment_to_Continuing_Disclosure_Undertaking_dated_01_05_2024__392_KB_.pdf\n",
      "Extracting data from Audited_Financials_and_Operating_Data_for_the_year_ended_06_30_2024_Document1__561_KB_.pdf\n",
      "Extracting data from Audited_Financials_and_Operating_Data_for_the_year_ended_06_30_2024_Document2__174_KB_.pdf\n",
      "Saved output to output_fin_nk_v8/ST_LOUIS_UNIVERSITY_US.xlsx\n",
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# Loop over schools\n",
    "for school in sorted(os.listdir(PDF_ROOT)):\n",
    "    school_dir = os.path.join(PDF_ROOT, school)\n",
    "    if not os.path.isdir(school_dir):\n",
    "        continue\n",
    "    print(f\"Processing school: {school}\")\n",
    "    process_school(school, school_dir)\n",
    "\n",
    "print(\"Extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b385406-d4f6-48e5-94b5-f999ee2e9f04",
   "metadata": {},
   "source": [
    "The following cell block extracts all the schools' info into one excel sheet but in different tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbed9f78-2b07-4696-8bd9-2ad2281d255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from BRADLEY_UNIVERSITY/Annual_Financial_Information_and_Operating_Data__Rule_15c2-12__for_FY24_for_the_year_ended_05_31_2024__227_KB_.pdf\n",
      "Extracting data from BRADLEY_UNIVERSITY/Audited_Financial_Statements_or_ACFR__Rule_15c2-12__for_FY24_for_the_year_ended_05_31_2024__541_KB_.pdf\n",
      "Extracting data from CORNELL_UNIVERSITY/2024_Audited_Financial_Statements_for_the_year_ended_06_30_2024__788_KB_.pdf\n",
      "Extracting data from CORNELL_UNIVERSITY/2024_Operating_Data_for_the_year_ended_06_30_2024__109_KB_.pdf\n",
      "Extracting data from CORNELL_UNIVERSITY/Incorporate_OS_by_Reference_as_of_04_25_2024__2.4_MB_.pdf\n",
      "Extracting data from CULINARY_INSTITUTE_OF_AMERICA_THE/2024_Annual_Report_-_Corrected_for_the_year_ended_05_31_2024__130_KB_.pdf\n",
      "Extracting data from CULINARY_INSTITUTE_OF_AMERICA_THE/2024_Annual_Report_for_the_year_ended_05_31_2024__129_KB_.pdf\n",
      "Extracting data from CULINARY_INSTITUTE_OF_AMERICA_THE/2024_Audited_Financial_Statements_for_the_year_ended_05_31_2024__277_KB_.pdf\n",
      "Extracting data from GANNON_UNIVERSITY/Audited_Financial_Statements_for_the_year_ended_06_30_2024__786_KB_.pdf\n",
      "Extracting data from GANNON_UNIVERSITY/Continued_Disclosures_Fall_2024_for_the_year_ended_06_30_2024_Document1__203_KB_.pdf\n",
      "Extracting data from LEWIS_UNIVERSITY/Audited_Financial_Statements_for_the_year_ended_06_30_2024__430_KB_.pdf\n",
      "Extracting data from LEWIS_UNIVERSITY/Continuing_Disclosure_for_the_year_ended_06_30_2024__298_KB_.pdf\n",
      "Extracting data from MOLLOY_COLLEGE/Financial_Operating_Filing_for_the_year_ended_06_30_2024_Document1__304_KB_.pdf\n",
      "Extracting data from MOLLOY_COLLEGE/Financial_Operating_Filing_for_the_year_ended_06_30_2024_Document2__142_KB_.pdf\n",
      "Extracting data from MOUNT_ST_MARY_S_UNIVERSITY_INC/Audited_Annual_Financials_for_the_year_ended_06_30_2024_Document1__29.1_MB_.pdf\n",
      "Extracting data from MOUNT_ST_MARY_S_UNIVERSITY_INC/Audited_Annual_Financials_for_the_year_ended_06_30_2024_Document2__5_MB_.pdf\n",
      "Extracting data from NEW_YORK_UNIVERSITY/2024_Certificate_of_Compliance_-_Audit_for_the_year_ended_06_30_2024__330_KB_.pdf\n",
      "Extracting data from NEW_YORK_UNIVERSITY/2024_Certificate_of_Compliance_for_the_year_ended_06_30_2024__323_KB_.pdf\n",
      "Extracting data from NEW_YORK_UNIVERSITY/2024_Consolidated_Financial_Statements_New_York_University_for_the_year_ended_06_30_2024__466_KB_.pdf\n",
      "Extracting data from NEW_YORK_UNIVERSITY/2024_Operating_Data_for_the_year_ended_06_30_2024__244_KB_.pdf\n",
      "Extracting data from PRESIDENT___FELLOWS_OF_HARVARD_COLLEGE/Harvard_University_Audited_Financial_Information_for_the_year_ended_06_30_2024__10.6_MB_.pdf\n",
      "Extracting data from PRESIDENT___FELLOWS_OF_HARVARD_COLLEGE/Harvard_University_Financial_Report_for_the_year_ended_06_30_2024__10.6_MB_.pdf\n",
      "Extracting data from PRESIDENT___FELLOWS_OF_HARVARD_COLLEGE/Harvard_University_Student_Applications_and_Enrollment_for_the_year_ended_06_30_2024__557_KB_.pdf\n",
      "Extracting data from STEVENSON_UNIVERSITY_INC/2024_Annual_Compliance_Certificate__EagleBank__for_the_year_ended_06_30_2024__3_MB_.pdf\n",
      "Extracting data from STEVENSON_UNIVERSITY_INC/2024_Annual_Compliance_Certificate_for_the_year_ended_06_30_2024__2.8_MB_.pdf\n",
      "Extracting data from STEVENSON_UNIVERSITY_INC/2024_Audited_Financial_Statements_for_the_year_ended_06_30_2024__348_KB_.pdf\n",
      "Extracting data from STEVENSON_UNIVERSITY_INC/2024_Operating_Data_for_the_year_ended_06_30_2024__196_KB_.pdf\n",
      "Extracting data from STEVENS_INSTITUTE_OF_TECHNOLOGY/Annual_Report_for_the_year_ended_06_30_2024__216_KB_.pdf\n",
      "Extracting data from STEVENS_INSTITUTE_OF_TECHNOLOGY/Audit_Financial_Statement_for_the_year_ended_06_30_2024__626_KB_.pdf\n",
      "Extracting data from ST_LOUIS_UNIVERSITY_US/Amendment_to_Continuing_Disclosure_Undertaking_dated_01_05_2024__392_KB_.pdf\n",
      "Extracting data from ST_LOUIS_UNIVERSITY_US/Audited_Financials_and_Operating_Data_for_the_year_ended_06_30_2024_Document1__561_KB_.pdf\n",
      "Extracting data from ST_LOUIS_UNIVERSITY_US/Audited_Financials_and_Operating_Data_for_the_year_ended_06_30_2024_Document2__174_KB_.pdf\n",
      "All schools written to output_fin_nk_v8/all_schools.xlsx\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = os.path.join(OUTPUT_ROOT, \"all_schools.xlsx\")\n",
    "\n",
    "writer = pd.ExcelWriter(OUTPUT_FILE, engine=\"openpyxl\")\n",
    "\n",
    "for school in sorted(os.listdir(PDF_ROOT)):\n",
    "    school_dir = os.path.join(PDF_ROOT, school)\n",
    "    if not os.path.isdir(school_dir):\n",
    "        continue\n",
    "\n",
    "    combined   = {}\n",
    "    first_keys = None\n",
    "    for fname in sorted(os.listdir(school_dir)):\n",
    "        if not fname.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "        path = os.path.join(school_dir, fname)\n",
    "        print(f\"Extracting data from {school}/{fname}\")\n",
    "        try:\n",
    "            run  = agent.extract(path)\n",
    "            data = run.data or {}\n",
    "            if first_keys is None:\n",
    "                first_keys = list(data.keys())\n",
    "                combined  = {k: None for k in first_keys}\n",
    "            for k, v in data.items():\n",
    "                if v not in (None, \"\", []):\n",
    "                    combined[k] = v\n",
    "        except Exception as err:\n",
    "            print(f\"Skipped {fname}: {err}\")\n",
    "\n",
    "    if first_keys:\n",
    "        df = pd.DataFrame.from_dict(combined, orient=\"index\", columns=[\"2024-25\"])\n",
    "        df.index.name = \"Metric\"\n",
    "        sheet_name = school[:31]\n",
    "        df.to_excel(writer, sheet_name=sheet_name)\n",
    "    else:\n",
    "        print(f\"No data for {school}.\")\n",
    "\n",
    "writer.close()\n",
    "print(f\"All schools written to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47a6c073-4b51-4770-abc4-f5942a1f772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: output_fin_nk_v8/all_schools_combined.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Combine all the tabs into one sheet if wanted\n",
    "file_path   = \"output_fin_nk_v8/all_schools.xlsx\"\n",
    "output_path = \"output_fin_nk_v8/all_schools_combined.xlsx\"\n",
    "\n",
    "raw = pd.read_excel(file_path, sheet_name=None, index_col=0)\n",
    "\n",
    "school_series = {\n",
    "    school: df.iloc[:, 0]                      # first (only) value column\n",
    "    for school, df in raw.items()\n",
    "}\n",
    "\n",
    "df_comb = pd.DataFrame(school_series).T\n",
    "df_comb.index.name = \"School\"                 \n",
    "df_comb.insert(0, \"Year\", \"2023‑2024\")\n",
    "\n",
    "# df_comb.loc['California_state_university', 'Undergraduate_Headcount'] = None \n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    df_comb.to_excel(writer, sheet_name=\"Combined\")\n",
    "\n",
    "print(\"Saved:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5ba9c-4240-49fe-8707-9c4fde4a09b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
