{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9627dd-5608-4da8-9f1a-8ea9589a003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "import pandas as pd\n",
    "from llama_cloud_services import LlamaExtract\n",
    "from llama_cloud.types import ExtractConfig, ExtractMode\n",
    "from income import generate_income_statement_schema \n",
    "import os, re, pathlib, tempfile, shutil\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf875a82-1028-4b54-8807-1d1dde9cca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "FISCAL_YEAR = 2024  #Change the year if you want different years\n",
    "IncomeStatement_2024_25 = generate_income_statement_schema(FISCAL_YEAR)\n",
    "PDF_ROOT = \"sample\" \n",
    "# PDF_ROOT = \"templates/data\"  # Change this to the point to the directory where you are storing the pdfs after scraping, also this is your input directory\n",
    "TARGET_DIR = \"templates\" # output directory\n",
    "os.makedirs(TARGET_DIR, exist_ok=True)\n",
    "OUTPUT_FILE = os.path.join(TARGET_DIR, \"all_schools_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47855a29-4fc8-4dae-b036-4626be1954da",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_ID = \"49cba8ec-d3b6-4a1a-a914-32b81d3ce7ad\" # all multi model\n",
    "# AGENT_ID = \"87c36b46-e9f0-4737-8467-355b3865bfc4\" # all balance model\n",
    "\n",
    "load_dotenv() #make sure the API key is in the .env file\n",
    "\n",
    "extractor = LlamaExtract(project_id = '8c10e62e-3810-4193-915d-d2d11105826d')\n",
    "\n",
    "agent = extractor.get_agent(id = AGENT_ID)\n",
    "\n",
    "agent.data_schema = IncomeStatement_2024_25\n",
    "agent.save()\n",
    "agent = extractor.get_agent(id = AGENT_ID)\n",
    "agent.data_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449229a-af1c-4e6f-8219-6497a0a1bc94",
   "metadata": {},
   "source": [
    "The following two cell blocks extract all schools' info into one csv file per school in the csv_outputs folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6cb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\n",
    "    OUTPUT_FILE,\n",
    "    engine=\"xlsxwriter\",\n",
    "    engine_kwargs={\"options\": {\"use_zip64\": True}}\n",
    ")\n",
    "\n",
    "def is_pdf(name: str) -> bool:\n",
    "    return name.lower().endswith(\".pdf\")\n",
    "\n",
    "OUTPUT_DIR = \"templates/csv_outputs\" # set folder\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "for school in sorted(os.listdir(PDF_ROOT)):\n",
    "    school_dir = os.path.join(PDF_ROOT, school)\n",
    "    if not os.path.isdir(school_dir) or school.startswith(\".\"):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n=== {school} ===\")\n",
    "    combined = {}\n",
    "    first_keys = None\n",
    "    pdfs = [f for f in sorted(os.listdir(school_dir)) if is_pdf(f)]\n",
    "\n",
    "    if not pdfs:\n",
    "        print(\"  (no PDFs found)\")\n",
    "        continue\n",
    "\n",
    "    for fname in pdfs:\n",
    "        path = os.path.join(school_dir, fname)\n",
    "        print(f\"Extracting data from {school}/{fname}\")\n",
    "\n",
    "        try:\n",
    "            run  = agent.extract(path)\n",
    "            data = run.data or {}\n",
    "            if first_keys is None:\n",
    "                first_keys = list(data.keys())\n",
    "                combined  = {k: None for k in first_keys}\n",
    "            for k, v in data.items():\n",
    "                if v not in (None, \"\", []):\n",
    "                    combined[k] = v\n",
    "        except Exception as err:\n",
    "            print(f\"Skipped {fname}: {err}\")\n",
    "\n",
    "    if first_keys:\n",
    "        df = pd.DataFrame.from_dict(combined, orient=\"index\", columns=[f\"{FISCAL_YEAR - 1}-{str(FISCAL_YEAR)[-2:]}\"])\n",
    "        df.index.name = \"Metric\"\n",
    "        sheet_name = school[:31]\n",
    "        \n",
    "        year = f\"{FISCAL_YEAR - 1}-{str(FISCAL_YEAR)[-2:]}\"    \n",
    "        # Fill NA by using instructional_research_expense  =  instructional_expense + research_expense\n",
    "        if pd.isna(df.loc['instructional_research_expense'].iloc[0]) and (not pd.isna(df.loc['instructional_expense'].iloc[0]) or not pd.isna(df.loc['research_expense'].iloc[0])):\n",
    "            df.loc['instructional_research_expense'] = (df.loc['instructional_expense'].iloc[0] + df.loc['research_expense'].iloc[0])\n",
    "        \n",
    "        #Create new variable  non_op_realized_investment_net_without_donor = non_op_realized_investment_net_without_donor \n",
    "        # - (extraordinary_gain_or_loss + net_assets_released_for_capital + change_fair_value_derivatives+ capital_grants_gifts)\n",
    "        if (\n",
    "            not pd.isna(df.loc['non_op_realized_investment_net_without_donor'].iloc[0])\n",
    "            or not pd.isna(df.loc['extraordinary_gain_or_loss'].iloc[0])\n",
    "            or not pd.isna(df.loc['net_assets_released_for_capital'].iloc[0])\n",
    "            or not pd.isna(df.loc['change_fair_value_derivatives'].iloc[0])\n",
    "            or not pd.isna(df.loc['capital_grants_gifts'].iloc[0])\n",
    "        ):\n",
    "            df.loc['other_non_op'] = (\n",
    "                df.loc['non_op_realized_investment_net_without_donor'].iloc[0]\n",
    "                - (\n",
    "                    df.loc['extraordinary_gain_or_loss'].iloc[0]\n",
    "                    + df.loc['net_assets_released_for_capital'].iloc[0]\n",
    "                    + df.loc['change_fair_value_derivatives'].iloc[0]\n",
    "                    + df.loc['capital_grants_gifts'].iloc[0]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        df.to_excel(writer, sheet_name=sheet_name)\n",
    "        if os.path.exists(\"templates/final.parquet\"):\n",
    "            existing = pd.read_parquet(\"templates/final.parquet\")\n",
    "            df['school'] = school\n",
    "            combined = pd.concat([existing, df])\n",
    "        else:\n",
    "            df['school'] = school\n",
    "            combined = df\n",
    "        combined.to_parquet(\"templates/final.parquet\", index=True)\n",
    "    if not df.empty:\n",
    "        output_file = os.path.join(OUTPUT_DIR, f\"{school}.csv\")\n",
    "        df.to_csv(output_file, index=True) # write to csv file\n",
    "        print(f\"Saved {school} to {output_file}\")\n",
    "    else:\n",
    "        print(f\"No data for {school}.\")\n",
    "    # save results to parquet format\n",
    "    df.to_parquet(\"templates/final.parquet\", index=True)\n",
    "\n",
    "    # Write via temp file + ZIP64; then atomic move\n",
    "    dest = pathlib.Path(OUTPUT_FILE) \n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        tmp = pathlib.Path(td) / dest.name\n",
    "        with pd.ExcelWriter(\n",
    "            tmp,\n",
    "            engine=\"xlsxwriter\",\n",
    "            engine_kwargs={\"options\": {\"use_zip64\": True, \"strings_to_urls\": False}}\n",
    "        ) as writer:\n",
    "            df.to_excel(writer, sheet_name=sheet_name)\n",
    "        shutil.move(str(tmp), dest)\n",
    "\n",
    "    print(f\"All schools written to {dest}\")\n",
    "\n",
    "writer.close()\n",
    "print(f\"All schools written to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case experiencing operation time out for Excel, we sort the data in csv and store it to the \"all_schools_combined_test\"\n",
    "# Path to the folder where your CSV files are stored\n",
    "CSV_DIR = \"templates/csv_outputs\"\n",
    "OUTPUT_FILE = \"templates/all_schools_combined_test.xlsx\"\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for fname in sorted(os.listdir(CSV_DIR)):\n",
    "    if not fname.endswith(\".csv\"):\n",
    "        continue\n",
    "    path = os.path.join(CSV_DIR, fname)\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Clean up\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    df[\"Metric\"] = df[\"Metric\"].astype(str).str.strip()\n",
    "    df = df.dropna(subset=[\"Metric\"]).drop_duplicates(subset=[\"Metric\"], keep=\"last\")\n",
    "\n",
    "    # Get university name (prefer the column; fall back to file name)\n",
    "    school = (\n",
    "        df.get(\"school\").dropna().iloc[0]\n",
    "        if \"school\" in df.columns and df[\"school\"].notna().any()\n",
    "        else fname.replace(\".csv\", \"\")\n",
    "    )\n",
    "\n",
    "    series = (\n",
    "        df.set_index(\"Metric\")[\"2023-24\"]\n",
    "          .rename(school)\n",
    "          .apply(pd.to_numeric, errors=\"coerce\")\n",
    "    )\n",
    "    rows.append(series)\n",
    "\n",
    "# Combine to a DataFrame: index = schools, columns = metrics\n",
    "combined = pd.DataFrame(rows)\n",
    "\n",
    "# Sort: rows by university, columns (metrics) alphabetically\n",
    "combined = combined.sort_index(axis=0)\n",
    "combined = combined.reindex(sorted(combined.columns), axis=1)\n",
    "\n",
    "combined.index.name = \"school\"\n",
    "combined.to_excel(OUTPUT_FILE) # save to excel\n",
    "\n",
    "print(f\"Saved: {OUTPUT_FILE}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
