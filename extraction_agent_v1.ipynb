{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c9627dd-5608-4da8-9f1a-8ea9589a003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from llama_cloud_services import LlamaExtract\n",
    "from schemas import Enrollment2024_25  #This could be adjusted through schemas.py\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf875a82-1028-4b54-8807-1d1dde9cca33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF_ROOT = \"university_pdfs_test\"\n",
    "OUTPUT_ROOT = \"output_1\"\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)  \n",
    "AGENT_ID = \"6edffe95-2dac-4992-8f32-7c179c60850a\" #Different based on your LLamaCloud account\n",
    "load_dotenv() #make sure the API key is in the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47855a29-4fc8-4dae-b036-4626be1954da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No project_id provided, fetching default project.\n"
     ]
    }
   ],
   "source": [
    "extractor = LlamaExtract()\n",
    "\n",
    "#uncomment the below line if you are creating the agent for the first time\n",
    "# agent = extractor.create_agent(name = \"enrollment-parser-2024\", data_schema=Enrollment2024_25)\n",
    "\n",
    "agent = extractor.get_agent(id = AGENT_ID)\n",
    "\n",
    "#uncomment the following lines if you updated the schema\n",
    "agent.data_schema = Enrollment2024_25\n",
    "agent.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449229a-af1c-4e6f-8219-6497a0a1bc94",
   "metadata": {},
   "source": [
    "The following two cell blocks extract all schools' info into one excel file per school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36077e96-e5ec-4352-afef-d76b8f78be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_school(school_name, school_dir):\n",
    "    combined   = {}\n",
    "    first_keys = None\n",
    "\n",
    "    for fname in sorted(os.listdir(school_dir)):\n",
    "        if not fname.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "        path = os.path.join(school_dir, fname)\n",
    "        print(f\"Extracting data from {fname}\")\n",
    "        try:\n",
    "            run  = agent.extract(path)\n",
    "            data = run.data or {}\n",
    "            if first_keys is None:\n",
    "                first_keys = list(data.keys())\n",
    "                combined  = {k: None for k in first_keys}\n",
    "            for k, v in data.items():\n",
    "                if v not in (None, \"\", []):\n",
    "                    combined[k] = v\n",
    "        except Exception as err:\n",
    "            print(f\"Skipped {fname}: {err}\")\n",
    "\n",
    "    if first_keys:\n",
    "        df = pd.DataFrame.from_dict(combined, orient=\"index\", columns=[\"2024-25\"])\n",
    "        df.index.name = \"Metric\"\n",
    "        outfile = os.path.join(OUTPUT_ROOT, f\"{school_name}.xlsx\")\n",
    "        df.to_excel(outfile)\n",
    "        print(f\"Saved output to {outfile}\")\n",
    "    else:\n",
    "        print(f\"No PDF data found for {school_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7256b8f-8158-48f2-8b89-5e1ae36760c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over schools\n",
    "for school in sorted(os.listdir(PDF_ROOT)):\n",
    "    school_dir = os.path.join(PDF_ROOT, school)\n",
    "    if not os.path.isdir(school_dir):\n",
    "        continue\n",
    "    print(f\"Processing school: {school}\")\n",
    "    process_school(school, school_dir)\n",
    "\n",
    "print(\"Extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b385406-d4f6-48e5-94b5-f999ee2e9f04",
   "metadata": {},
   "source": [
    "The following cell block extracts all the schools' info into one excel sheet but in different tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbed9f78-2b07-4696-8bd9-2ad2281d255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from ASU/P11817713-P11393130-P11833489.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [01:11<00:00, 71.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from Bradley University/P21862068-P21425154-P21869099.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [00:38<00:00, 38.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from California_state_university/P21878315-P21436983-P21882690.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [00:56<00:00, 56.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from Cornell_university/P11799657-P11380074-P11818843.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [00:54<00:00, 55.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from Culinary_institute_of_America/P11790595-P11373821-P11811978.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.52it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [01:16<00:00, 76.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from Gannon_university/P21859160-P21423095-P21866877.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [00:38<00:00, 38.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from Harvard_university/P21889042-P21444694-P21891364.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "Extracting files: 100%|██████████████████████████████████| 1/1 [02:21<00:00, 141.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from Lewis_univsersity/P11819634-P11394595-P11835096.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [01:25<00:00, 85.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from MT_ST_MARY/Mt St Mary's fall 24 continuing disclosure.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Extracting files: 100%|██████████████████████████████████| 1/1 [02:19<00:00, 139.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from Michigan_state_university/P21870305-P21430806-P21875444.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [00:40<00:00, 40.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from Molloy_college/P21874771-P21434198-P21879428.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [01:06<00:00, 66.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from New_York_University/P11812334-P11389223-P11829036.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [01:05<00:00, 65.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from Ohio_state/P21875437-P21434721-P21880042.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [01:23<00:00, 83.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from ST_Louis_univ/P21874807-P21434222-P21879459.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [00:38<00:00, 38.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from Stevenson/P21870783-P21431172-P21875933.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.71it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [01:25<00:00, 85.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from Texas_A&M/P21898799-P21452091-P21899985.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [01:25<00:00, 85.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from The_catholic_university_of_america/P21849198-P11371813-P21859547.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [00:55<00:00, 55.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from University_of_colorado/P21915816-P21464707-P21913817.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.50it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [00:55<00:00, 55.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from University_of_minesota/P11814086-P21430908-P11830336.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [00:49<00:00, 49.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from stevens_institue_of_technology/P21870185-P21430712-P21875325.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Creating extraction jobs: 100%|███████████████████████████| 1/1 [00:00<00:00,  2.46it/s]\n",
      "Extracting files: 100%|███████████████████████████████████| 1/1 [00:31<00:00, 31.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All schools written to output_1/all_schools.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = os.path.join(OUTPUT_ROOT, \"all_schools.xlsx\")\n",
    "\n",
    "writer = pd.ExcelWriter(OUTPUT_FILE, engine=\"openpyxl\")\n",
    "\n",
    "for school in sorted(os.listdir(PDF_ROOT)):\n",
    "    school_dir = os.path.join(PDF_ROOT, school)\n",
    "    if not os.path.isdir(school_dir):\n",
    "        continue\n",
    "\n",
    "    combined   = {}\n",
    "    first_keys = None\n",
    "    for fname in sorted(os.listdir(school_dir)):\n",
    "        if not fname.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "        path = os.path.join(school_dir, fname)\n",
    "        print(f\"Extracting data from {school}/{fname}\")\n",
    "        try:\n",
    "            run  = agent.extract(path)\n",
    "            data = run.data or {}\n",
    "            if first_keys is None:\n",
    "                first_keys = list(data.keys())\n",
    "                combined  = {k: None for k in first_keys}\n",
    "            for k, v in data.items():\n",
    "                if v not in (None, \"\", []):\n",
    "                    combined[k] = v\n",
    "        except Exception as err:\n",
    "            print(f\"Skipped {fname}: {err}\")\n",
    "\n",
    "    if first_keys:\n",
    "        df = pd.DataFrame.from_dict(combined, orient=\"index\", columns=[\"2024-25\"])\n",
    "        df.index.name = \"Metric\"\n",
    "        sheet_name = school[:31]\n",
    "        df.to_excel(writer, sheet_name=sheet_name)\n",
    "    else:\n",
    "        print(f\"No data for {school}.\")\n",
    "\n",
    "writer.close()\n",
    "print(f\"All schools written to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47a6c073-4b51-4770-abc4-f5942a1f772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: output_1/all_schools_combined.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Combine all the tabs into one sheet if wanted\n",
    "file_path   = \"output_1/all_schools.xlsx\"\n",
    "output_path = \"output_1/all_schools_combined.xlsx\"\n",
    "\n",
    "raw = pd.read_excel(file_path, sheet_name=None, index_col=0)\n",
    "\n",
    "school_series = {\n",
    "    school: df.iloc[:, 0]                      # first (only) value column\n",
    "    for school, df in raw.items()\n",
    "}\n",
    "\n",
    "df_comb = pd.DataFrame(school_series).T\n",
    "df_comb.index.name = \"School\"                 \n",
    "df_comb.insert(0, \"Year\", \"2024‑2025\")\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    df_comb.to_excel(writer, sheet_name=\"Combined\")\n",
    "\n",
    "print(\"Saved:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d653469-e4e7-4813-8b93-ea4c6ce9d715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
